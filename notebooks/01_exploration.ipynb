{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f92732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import io\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import google.auth\n",
    "from google.cloud import storage\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f094401",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = os.environ['BUCKET_NAME']\n",
    "SOURCE_FOLDER_ID = os.environ['FOLDER_ID']\n",
    "print(BUCKET_NAME)\n",
    "print(SOURCE_FOLDER_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf97d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b89ebaa3",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drive_service():\n",
    "    # Authenticates using the Cloud Run Service Account automatically\n",
    "    creds, _ = google.auth.default(\n",
    "        scopes=['https://www.googleapis.com/auth/drive.readonly']\n",
    "    )\n",
    "    return build('drive', 'v3', credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_service = get_drive_service()\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_service, storage_client, bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timestamped folder\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "backup_folder = f'backup_{timestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b7fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"'{SOURCE_FOLDER_ID}' in parents and trashed = false\"\n",
    "results = (\n",
    "    drive_service.files().list(q=query, fields='files(id, name, mimeType)').execute()\n",
    ")\n",
    "files = results.get('files', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_recursive(drive_service, bucket, folder_id, current_path):\n",
    "    \"\"\"Iterate trhough folders and upload files.\"\"\"\n",
    "    print(f'Scan folder: {current_path} ...')\n",
    "\n",
    "    # Pagination: If more thatn 100 files exists in a folder\n",
    "    page_token = None\n",
    "    while True:\n",
    "        # Search for all files/folder which parents is folder_id\n",
    "        query = f\"'{folder_id}' in parents and trashed = false\"\n",
    "\n",
    "        results = (\n",
    "            drive_service.files()\n",
    "            .list(\n",
    "                q=query,\n",
    "                fields='nextPageToken, files(id, name, mimeType)',\n",
    "                pageToken=page_token,\n",
    "            )\n",
    "            .execute()\n",
    "        )\n",
    "\n",
    "        items = results.get('files', [])\n",
    "\n",
    "        for item in items:\n",
    "            process_item(drive_service, bucket, item, current_path)\n",
    "\n",
    "        # Check if there is another page with results\n",
    "        page_token = results.get('nextPageToken')\n",
    "        if not page_token:\n",
    "            break\n",
    "\n",
    "\n",
    "def upload_file(drive_service, bucket, file_id, mime_type, blob_path):\n",
    "    \"\"\"Upload the file to GCS bucket\"\"\"\n",
    "    blob = bucket.blob(blob_path)\n",
    "\n",
    "    # Skip if file already exists\n",
    "    if blob.exists():\n",
    "        print(f'Skip file (already exists): {blob_path}')\n",
    "        return\n",
    "\n",
    "    # Convert Google File (docs, sheets) to pdf\n",
    "    if 'application/vnd.google-apps' in mime_type:\n",
    "        print(f'Convert to PDF: {blob_path}')\n",
    "        request = drive_service.files().export_media(\n",
    "            fileId=file_id, mimeType='application/pdf'\n",
    "        )\n",
    "        blob.name += '.pdf'\n",
    "\n",
    "    # Regular files\n",
    "    else:\n",
    "        print(f'Download: {blob_path}')\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "\n",
    "    # Stream Upload\n",
    "    fh = io.BytesIO()\n",
    "    downloader = MediaIoBaseDownload(fh, request)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        status, done = downloader.next_chunk()\n",
    "\n",
    "    fh.seek(0)\n",
    "    blob.upload_from_file(fh)\n",
    "    print(f'Saved: {blob_path}')\n",
    "\n",
    "\n",
    "def process_item(drive_service, bucket, item, current_path):\n",
    "    \"\"\"Decides if it is a folder (recursion) or a file (upload)!\"\"\"\n",
    "    file_id = item['id']\n",
    "    file_name = item['name']\n",
    "    mime_type = item['mimeType']\n",
    "\n",
    "    # Remove slash in file name for save GCS handling\n",
    "    safe_name = file_name.replace('/', '_')\n",
    "\n",
    "    # New path in GCS bucket\n",
    "    full_blob_path = f'{current_path}/{safe_name}'\n",
    "\n",
    "    # Case 1: FOLDER\n",
    "    if mime_type == 'application/vnd.google-apps.folder':\n",
    "        # Recall the backup function for new folder\n",
    "        backup_recursive(drive_service, bucket, file_id, full_blob_path)\n",
    "\n",
    "    # Case 2: FILE\n",
    "    else:\n",
    "        upload_file(drive_service, bucket, file_id, mime_type, full_blob_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb204140",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "root_backup_folder = f'backup_{timestamp}'\n",
    "\n",
    "backup_recursive(drive_service, bucket, SOURCE_FOLDER_ID, root_backup_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
